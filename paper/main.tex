%
% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}

%
% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
% Rights management information. 
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.
\copyrightyear{2019}
\acmYear{2019}
\setcopyright{acmlicensed}
\acmConference[DEBS '19]{DEBS '19: ACM International Conference on Distributed and Event-Based Systems.}{June 24--28, 2019}{Darmstadt, Darmstadt}
\acmBooktitle{DEBS '19: ACM International Conference on Distributed and Event-Based Systems, June 24--28, 2019, Darmstadt, Darmstadt}
\acmPrice{15.00}
\acmDOI{10.1145/1122445.1122456}
\acmISBN{978-1-4503-9999-9/18/06}

%
% These commands are for a JOURNAL article.
%\setcopyright{acmcopyright}
%\acmJournal{TOG}
%\acmYear{2018}\acmVolume{37}\acmNumber{4}\acmArticle{111}\acmMonth{8}
%\acmDOI{10.1145/1122445.1122456}

%
% Submission ID. 
% Use this when submitting an article to a sponsored event. You'll receive a unique submission ID from the organizers
% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{123-A56-BU3}

%
% The majority of ACM publications use numbered citations and references. If you are preparing content for an event
% sponsored by ACM SIGGRAPH, you must use the "author year" style of citations and references. Uncommenting
% the next command will enable that style.
%\citestyle{acmauthoryear}





% HERE STARTS OUR packages 

% \usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)

% \usepackage{multirow}
% \usepackage [table]{xcolor}

% \usepackage{graphicx}
% \usepackage{color}
% \usepackage{times}
%\usepackage{url}
%\usepackage[utf8]{inputenc}
%\usepackage{soul}
%\usepackage{nameref} 
%\usepackage{amsbsy}
% \usepackage{bezier}  
% \usepackage{colortbl}
% \usepackage{verbatim}
%\usepackage{qtree}
% \usepackage{xcolor}
% \usepackage{xspace}
% \usepackage{rotating}
% \usepackage{multirow}
%\usepackage{hyperref}
%\usepackage[capitalize]{cleveref}
% \usepackage{todonotes}
% \usepackage{microtype}
% \usepackage{fmtcount}
% \usepackage{datetime}
%\usepackage{tikz}
% \usepackage{pgfplots}
% \usepackage{tcolorbox}
% \usepackage{subfig}
%\usepackage{fancyvrb}

%\usepackage{fancyvrb}
% \usepackage{float}
%\usepackage{mathpazo}
% \usepackage[boxruled,slide,lined]{algorithm2e}

%\usepackage{caption}
% \usepackage{graphicx}
% \usepackage{subcaption}
% \usepackage{graphicx}
%\usepackage{courier}
% \usepackage{cleveref}
% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{latexsym}
% \usepackage{bm}
% \usepackage{subscript}
% \usepackage{multirow}
%\usepackage{tgheros}
% \usepackage{hyperref}
% \usepackage{subfig}

% \usepackage{listings}
% 
% \lstset{
% language=Java,                  % the language of the code
% basicstyle=\scriptsize,        % the size of the fonts that are used for the code
% basicstyle=\ttfamily,           % the font used for the code
% backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
% showspaces=false,               % show spaces adding particular underscores
% showstringspaces=false,         % underline spaces within strings
% showtabs=false,                 % show tabs within strings adding particular underscores
% frame=none,                     % adds a frame around the code, none, single 
% tabsize=1,                   	% sets default tabsize to 2 spaces
% captionpos=b,                  	% sets the caption-position to bottom
% breaklines=flase,                % sets automatic line breaking
% % breakatwhitespace=false,      % sets if automatic breaks should only happen at whitespace
% title=\lstname,                 % show the filename of files included with \lstinputlisting;
%                                 % also try caption instead of title
% escapeinside={\%*}{*)},         % if you want to add a comment within your code
% morekeywords={*,...},            % if you want to add more keywords to the set
% belowcaptionskip=-1.6em,
% belowskip=0em,
% framexleftmargin=10pt
% }
% 
% 
% 
% \newcommand{\TODO}[1]{\todo[inline,color=orange!40]{KIA: #1}}


%
% end of the preamble, start of the body of the document source.
\begin{document}

%
% The "title" command has an optional parameter, allowing the author to define a "short title" to be used in page headers.
% \title{Grand Challenge: A Real-Time Multi-label Classifier for High-Speed Streaming Data}

\title{Grand Challenge: Real-Time Object Recognition from Streaming LiDAR Point Cloud Data}


%
% The "author" command and its associated commands are used to define the authors and their affiliations.
% Of note is the shared affiliation of the first two authors, and the "authornote" and "authornotemark" commands
% used to denote shared contribution to the research.


\author{Sambasiva Rao Gangineni}
\affiliation{%
  \institution{Boston University}  
}
\email{samba693@bu.edu}

\author{Harshad Reddy Nalla}
\affiliation{%
	\institution{Boston University}  
}
\email{harshad@bu.edu}

% \author{Dimitrije Jankov}
% \affiliation{%
% 	\institution{Rice University}  
% }
% \email{dimitrijejankov@gmail.com}

\author{Saeed Fathollahzadeh}
\affiliation{%
	\institution{Iran University of Science and Technology}  
}
\email{fathollahzadeh@comp.iust.ac.ir}

\author{Kia Teymourian}
\affiliation{%
  \institution{Boston University}
 }
\email{kiat@bu.edu}



%
% By default, the full list of authors will be used in the page headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows the author to define a more concise list
% of authors' names for this purpose.
\renewcommand{\shortauthors}{Gangineni, et al.}

%
% The abstract is a short summary of the work to be presented in the article.
\begin{abstract}
Recognition of objects surrounding a robot in a dynamic environment is one of the research challenges in robotics.
LiDAR (Light Direction and Ranging) Laser scanner is used in many applications to surveying

% Many real-world applications include multi-lable data and require real-time high-speed multi-lable classification. 
% In most application, it is crucial to proactively react based on classification results. 
% For example, in autonomous car application it is important to detect surrounding cars and pedestrians in real-time to send reaction signals.  


We describe in this paper, our implementation for DEBS 2019 Grand Challenge for a high-speed online neural network classifier 
that is highly customized to classify objects from streaming data in real-time.
\end{abstract}


% \begin{abstract}
% Many real-world applications include multi-lable data and require real-time high-speed multi-lable classification. In most application, it is crucial to proactively react based on classification results. For example, in autonomous car application it is important to detect surrounding cars and pedestrians in real-time to send reaction signals.  We describe in this paper, our implementation for DEBS 2019 Grand Challenge for a high-speed online neural network classifier that is highly customized to classify objects from streaming data in real-time.
% \end{abstract}



%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information Systems~Machine Learning}
\ccsdesc[300]{Information Systems~Data Stream}

%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.
\keywords{Neural Networks, Object Recognition, Multi-Label Classification, Data Stream Processing}



%
% This command processes the author and affiliation and title information and builds
% the first part of the formatted document.
\maketitle

\section{Introduction}
One of the special and still not completely solved problems in robotics research, is the real-time object recognition surrounding an autonomous robot. Highly dynamic and rapidly changing environment of a robot requires a fast and intelligent system to detect its surrounding objects. Many applications like autonomous vehicles or autonomous cleaning robots require object recognition in real-time with high accuracy. 
For such applications, it is life-threatening to detect surrounding objects accurately in real-time and be able to react proactively based on object classification results. 

One of the surveying methods that is in such application is a LiDAR scanner (Light Direction and Ranging). Such laser scanner can be used to generate a three dimensional representation of the surrounding environment. 
It uses multiple lasers to generate a point cloud of coordinates (x,y,z) of objects. 
LiDAR point cloud includes data can be processed to recognize objects. This task includes a fast data process pipeline and an accurate learning model to learn and classify different object types. 

The ACM DEBS 2019 grand challenge \cite{DEBSGC2019} describes an object recognition challenge from stream of LiDAR point cloud data. 
The organizers of the challenge provide a training set of LiDAR data for 28 different object types like car (2 different types), pedestrian, trees (2 different types), ATM machine, pedestrian, benches, container. The DEBS 2019 challenge scenario, data set and evaluation criteria are described by  organizers Bodunov et al. in \cite{DEBSGC2019}. 


Our contributions in this paper are: 


\begin{enumerate}
  \item A brief state-of-the-art overview regarding object recognition from LiDAR point cloud.  (Sec. \ref{sec:relatedWork})
  \item Description of our data analysis architecture and processing pipeline including data pre-processing for LiDAR ground removal, data segmentation (generating voxels containing objects ), and multi-lable object classification  (Sec.  \ref{sec:Architecture}).
  \item Experimental evaluation and comparisons of different data processing architectures, different data models to achieve high accuracy 
  and real-time data processing (Sec. \ref{sec:Evaluation}).  
  \item A discussion about lessons learned and challenges (Sec. \ref{sec:conclusion} ). 
  % \item Future extensions of our implementation
\end{enumerate}    

  



  








\input{data}

\input{architecture}

\input{architecture2}


\input{evaluation}


\input{relatedWork}


\input{conclusion}


\bibliographystyle{ACM-Reference-Format}
\bibliography{refrences}




\end{document}
